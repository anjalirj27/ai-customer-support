ğŸ¤– AI-Powered Customer Support System

An AI-powered customer support platform built using a multi-agent architecture.
The system intelligently routes user queries to specialized agents (Support, Order, Billing) and responds using AI with database-backed context.

ğŸŒ Live Demo & Links

Frontend (Vercel):
ğŸ‘‰ https://ai-customer-support-hlm9nfv36-jinxs-projects-b8a1ef07.vercel.app/

Backend API (Railway):
ğŸ‘‰ https://web-production-b46fb.up.railway.app/

API Documentation (Swagger):
ğŸ‘‰ https://web-production-b46fb.up.railway.app/docs

Health Check:
ğŸ‘‰ https://web-production-b46fb.up.railway.app/api/health

âœ¨ Key Features

Multi-Agent Architecture

Router Agent (classifies user intent)

Support Agent (FAQs & general help)

Order Agent (orders, tracking, cancellation)

Billing Agent (payments, invoices, refunds)

AI-Powered Query Routing

Each user message is analyzed and routed to the correct agent automatically.

Tool-Enabled Agents

Agents use structured tools to fetch data from the database (orders, payments, conversations).

Context-Aware Conversations

Maintains conversation history to give relevant and consistent responses.

Rate Limiting

Prevents API abuse using request limits.

Live Frontend UI

Real-time chat interface with typing indicators and agent labels.

ğŸ§  How the System Works (High Level)

User sends a message from the frontend.

The Router Agent analyzes the message intent.

The message is delegated to the correct specialist agent.

The agent may use database tools if required.

AI generates a response using context + tools.

The response is stored and returned to the frontend.

ğŸ›  Tech Stack
Backend

FastAPI â€“ REST API

PostgreSQL â€“ Database

SQLAlchemy (Async) â€“ ORM

Groq AI (LLaMA 3) â€“ LLM provider

SlowAPI â€“ Rate limiting

Frontend

React

Vite

Axios

Lucide Icons

Deployment

Backend: Railway

Frontend: Vercel

ğŸ“¦ Project Structure
ai-customer-support/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ schemas/
â”‚   â”œâ”€â”€ core/
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â””â”€â”€ index.html
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

âš™ï¸ Setup Instructions
Prerequisites

Python 3.10+

Node.js 18+

PostgreSQL 15+

Groq API Key

ğŸš€ Backend Setup
python -m venv venv
venv\Scripts\activate

pip install -r requirements.txt

python create_database.py
python create_tables.py
python seed_database.py

uvicorn app.main:app --reload


Backend runs at:
ğŸ‘‰ http://127.0.0.1:8000

ğŸ¨ Frontend Setup
cd frontend
npm install
npm run dev


Frontend runs at:
ğŸ‘‰ http://localhost:5173

ğŸ” Environment Variables

Create a .env file in the root directory:

DATABASE_URL=postgresql+asyncpg://postgres:password@localhost:5432/customer_support

AI_PROVIDER=groq
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.3-70b-versatile

ğŸ”Œ API Endpoints
Chat

POST /api/chat/messages â€“ Send a message

GET /api/chat/conversations â€“ List conversations

GET /api/chat/conversations/{id} â€“ Get conversation details

Agents

GET /api/agents â€“ List available agents

GET /api/agents/{agent}/capabilities â€“ Agent capabilities

ğŸ§ª Example Query Flow

â€œWhere is my order ORD-2024-002?â€ â†’ Order Agent

â€œI want to check invoice INV-2024-004â€ â†’ Billing Agent

â€œHow do I reset my password?â€ â†’ Support Agent

ğŸ“Œ Highlights

Clean separation of concerns using agents

Beginner-friendly architecture

Production-ready API

Fully deployed and accessible online
